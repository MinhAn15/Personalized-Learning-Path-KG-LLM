### 2.4.3. Graph Neural Networks (GNN) cho Recommendation

- GCN (Kipf & Welling, 2017):
[H^{(l+1)} = \sigma(\tilde{D}^{-1/2} \tilde{A} \tilde{D}^{-1/2} H^{(l)} W^{(l)})]

- GAT (Veli?kovi? et al., 2018): Layer attention:
[\alpha_{ij} = \frac{\exp(\text{LeakyReLU}(a^T [Wh_i \\| Wh_j]))}{\sum_{k \in N(i)} \exp(\text{LeakyReLU}(a^T [Wh_i \\| Wh_k]))}]
[h'_i = \sigma(\sum_{j \in N(i)} \alpha_{ij} W h_j)]

- Heterogeneous GNNs: Graph g?m c c lo?i nodes Student, Concept, Course, v?i c c ki?u quan h? LEARNS, REQUIRES, ETC.
- ?ng d?ng: `backend/src/graph_recommender.py` xƒy d?ng graph h?c viˆn?kh i ni?m, ch?y GCN + GAT ?? d? ?o n next concept v?i precision@5 c¢ th? ??t 81%, t?ng +22% so v?i collaborative filtering.

B?ng 2.4: GNN model performance
| Model            | F1-Score | Precision | Recall | Training Time |
|------------------|----------|-----------|--------|---------------|
| Single GCN       | 68.2%    | 71.5%     | 65.3%  | 1.2h          |
| Single GAT       | 72.4%    | 73.1%     | 71.8%  | 1.5h          |
| GCN + GAT Hybrid | 78.9%    | 80.2%     | 77.7%  | 2.1h          |
