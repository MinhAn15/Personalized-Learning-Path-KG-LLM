
============================
NEO4J AURAFREE
+ UserName:neo4j
+ Password:qKMQOUIfeQVjAy2G4Lm0J_jSDBPwcUyggSla9q-AyiI
============================


=======================================================
call ngrok to connect Google Colab to Neo4j Desktop
+ngrok tcp 7687
=======================================================



======================================================
NEO4J QUERY CYPHER
// Load student nodes
LOAD CSV WITH HEADERS FROM 'file:///student.csv' AS row
MERGE (s:Student {id: row.StudentID})
SET s.learning_history = row.Learning_History,
    s.current_level = toFloat(row.Current_Level),
    s.timestamp = datetime(row.Timestamp),
    s.performance_details = row.Performance_Details,
    s.learning_style_preference = row.Learning_Style_Preference
RETURN count(s)


// Load student relationships (run separately)
LOAD CSV WITH HEADERS FROM 'file:///student_relationship.csv' AS row
MATCH (s:Student {id: row.Student_ID})
MATCH (n {id: row.Node_ID})
CALL apoc.merge.relationship(s, row.Relationship_Type, 
    {progress: toFloat(row.Progress), last_updated: row.Last_Updated}, 
    {progress: toFloat(row.Progress), last_updated: row.Last_Updated}, 
    n) YIELD rel
RETURN count(rel)

--------------------------------
//Load Relationship KNOWLEDGENODE
// Load relationships from CSV and create or merge relationships
LOAD CSV WITH HEADERS FROM 'file:///validated_relationships.csv' AS row

// Match source and target nodes based on node_id and document_id
MATCH (sourceNode:Node {node_id: row.Source_Node_ID, document_id: row.Document_ID})
MATCH (targetNode:Node {node_id: row.Target_Node_ID, document_id: row.Document_ID})

// Ensure both source and target nodes exist
WHERE sourceNode IS NOT NULL AND targetNode IS NOT NULL

// Merge the relationship with properties
MERGE (sourceNode)-[r:Relationship {relationship_type: row.Relationship_Type}]->(targetNode)
ON CREATE SET
    r.document_id = row.Document_ID,
    r.weight = toFloat(row.Weight),
    r.dependency = toFloat(row.Dependency)
ON MATCH SET
    r.document_id = coalesce(r.document_id, row.Document_ID),
    r.weight = coalesce(r.weight, toFloat(row.Weight)),
    r.dependency = coalesce(r.dependency, toFloat(row.Dependency))

// Return the count of created or merged relationships
RETURN count(r) AS relationship_count
------------------------------------------------------------------




-------------------------------------------------------------
// LOAD KNOWLEDGENODE
// Step 1: Load nodes from CSV and prepare properties
LOAD CSV WITH HEADERS FROM 'file:///validated_nodes.csv' AS row
WITH row,
     apoc.map.fromPairs([key IN keys(row) WHERE key STARTS WITH 'Key_Property_' | 
                         [key, row[key]]]) AS dynamic_properties
WITH row, dynamic_properties

// Step 2: Create or merge nodes based on Node_ID and Document_ID
MERGE (n:Node {node_id: row.Node_ID, document_id: row.Document_ID})
ON CREATE SET
    n.node_label = row.Node_Label,
    n.sanitized_concept = row.Sanitized_Concept,
    n.context = row.Context,
    n.definition = row.Definition,
    n.example = row.Example,
    n.learning_objective = row.Learning_Objective,
    n.skill_level = row.Skill_Level,
    n.time_estimate = toInteger(row.Time_Estimate),
    n.difficulty = row.Difficulty,
    n.priority = toInteger(row.Priority),
    n.prerequisites = split(row.Prerequisites, ','),
    n.semantic_tags = split(row.Semantic_Tags, ';'),
    n.focused_semantic_tags = split(row.Focused_Semantic_Tags, ';'),
    n += dynamic_properties
ON MATCH SET
    n.node_label = coalesce(n.node_label, row.Node_Label),
    n.sanitized_concept = coalesce(n.sanitized_concept, row.Sanitized_Concept),
    n.context = coalesce(n.context, row.Context),
    n.definition = coalesce(n.definition, row.Definition),
    n.example = coalesce(n.example, row.Example),
    n.learning_objective = coalesce(n.learning_objective, row.Learning_Objective),
    n.skill_level = coalesce(n.skill_level, row.Skill_Level),
    n.time_estimate = coalesce(n.time_estimate, toInteger(row.Time_Estimate)),
    n.difficulty = coalesce(n.difficulty, row.Difficulty),
    n.priority = coalesce(n.priority, toInteger(row.Priority)),
    n.prerequisites = coalesce(n.prerequisites, split(row.Prerequisites, ',')),
    n.semantic_tags = apoc.coll.union(n.semantic_tags, split(row.Semantic_Tags, ';')),
    n.focused_semantic_tags = apoc.coll.union(n.focused_semantic_tags, split(row.Focused_Semantic_Tags, ';')),
    n += dynamic_properties

// Step 3: Add labels dynamically based on Node_Label
CALL apoc.create.addLabels(n, [row.Node_Label]) YIELD node

// Step 4: Handle merging based on Jaccard similarity of Semantic_Tags
WITH node AS n
MATCH (existing:Node)
WHERE existing.node_id <> n.node_id AND apoc.coll.jaccardSimilarity(existing.semantic_tags, n.semantic_tags) > 0.7
WITH n, existing, apoc.coll.jaccardSimilarity(existing.semantic_tags, n.semantic_tags) AS similarity
ORDER BY similarity DESC
LIMIT 1
WITH n, existing

// Step 5: Merge properties and relationships
CALL apoc.refactor.mergeNodes([n, existing], {
  properties: "combine",
  mergeRels: true
}) YIELD node AS merged_node

// Step 6: Update merged node properties (prioritize non-"Not Available" values)
SET merged_node.definition = CASE WHEN merged_node.definition = 'Not Available' THEN n.definition ELSE merged_node.definition END,
    merged_node.example = CASE WHEN merged_node.example = 'Not Available' THEN n.example ELSE merged_node.example END,
    merged_node.learning_objective = CASE WHEN merged_node.learning_objective = 'Not Available' THEN n.learning_objective ELSE merged_node.learning_objective END,
    merged_node.skill_level = CASE WHEN merged_node.skill_level = 'Not Available' THEN n.skill_level ELSE merged_node.skill_level END,
    merged_node.time_estimate = CASE WHEN merged_node.time_estimate IS NULL THEN n.time_estimate ELSE merged_node.time_estimate END,
    merged_node.difficulty = CASE WHEN merged_node.difficulty = 'Not Available' THEN n.difficulty ELSE merged_node.difficulty END,
    merged_node.priority = CASE WHEN merged_node.priority IS NULL THEN n.priority ELSE merged_node.priority END,
    merged_node.prerequisites = apoc.coll.union(merged_node.prerequisites, n.prerequisites),
    merged_node.semantic_tags = apoc.coll.union(merged_node.semantic_tags, n.semantic_tags),
    merged_node.focused_semantic_tags = apoc.coll.union(merged_node.focused_semantic_tags, n.focused_semantic_tags)

// Step 7: Remove duplicates in list properties
SET merged_node.prerequisites = apoc.coll.toSet(merged_node.prerequisites),
    merged_node.semantic_tags = apoc.coll.toSet(merged_node.semantic_tags),
    merged_node.focused_semantic_tags = apoc.coll.toSet(merged_node.focused_semantic_tags)

// Step 8: Ensure dynamic properties are merged correctly
WITH merged_node, n
CALL apoc.create.setProperties(merged_node, keys(n), [key IN keys(n) | n[key]]) YIELD node
RETURN count(node) AS node_count
-------------------------------------------------------------


// Verify Knowledge Node
MATCH (n)
WHERE n.id IS NOT NULL
RETURN n.id, n.node_label, n.sanitized_concept, n.context, labels(n)
ORDER BY n.id


//Verify Relationship
MATCH (source)-[r]->(target)
RETURN source.id AS source_id, labels(source) AS source_labels, type(r) AS relationship_type, target.id AS target_id, labels(target) AS target_labels, r.document_id, r.weight, r.dependency
ORDER BY source.id, target.id


-----------------------------------------------------------
// Query to check after run
// 1. Total Nodes
MATCH (n)
WHERE n.Node_ID IS NOT NULL
RETURN count(n) AS total_nodes;

// 2. Total Relationships
MATCH ()-[r]->()
WHERE r.Weight IS NOT NULL OR r.Dependency IS NOT NULL
RETURN count(r) AS total_relationships;

// 3. Node with properties
MATCH (n)
RETURN n.Node_ID, labels(n) AS node_labels, n.Sanitized_Concept, n.Semantic_Tags, properties(n) AS node_properties
LIMIT 10;

// 4. Relationship with properties
MATCH (source)-[r]->(target)
RETURN source.Node_ID AS source_id, type(r) AS relationship_type, target.Node_ID AS target_id, properties(r) AS rel_properties
LIMIT 10;

// 5. Kiểm tra một node cụ thể và các mối quan hệ của nó
MATCH (n {Node_ID: "concept:variance"})-[r]->(related)
RETURN n.Node_ID AS node_id, labels(n) AS node_labels, properties(n) AS node_properties, 
       type(r) AS relationship_type, related.Node_ID AS related_node_id, properties(r) AS rel_properties;

// 6. Kiểm tra cấu trúc KG tổng quát
MATCH (n)-[r]->(m)
RETURN n.Node_ID AS source_id, labels(n) AS source_labels, type(r) AS relationship_type, 
       m.Node_ID AS target_id, labels(m) AS target_labels
LIMIT 10;

// 7. Truy vấn Cypher để lấy dữ liệu cho llama-index
MATCH (n)-[r]->(m)
RETURN 
    n.Node_ID AS node_id, 
    labels(n) AS node_labels, 
    properties(n) AS node_properties, 
    type(r) AS relationship_type, 
    m.Node_ID AS related_node_id, 
    properties(r) AS rel_properties
LIMIT 10;





---------------------------------------------
// 8. DELETE
// Xóa tất cả relationships trước
MATCH ()-[r]->()
DELETE r;

// Sau đó xóa tất cả nodes
MATCH (n)
DELETE n;


OR 


MATCH (n)
DETACH DELETE n;=====================================================================